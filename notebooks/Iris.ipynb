{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import auxiliary_fun as a\n",
    "import numpy as np\n",
    "import perceptron as p\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load iris dataset and keep just two of the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X1 = X[y==0]\n",
    "X2 = X[y==1]\n",
    "y1 = y[y==0]\n",
    "y2 = y[y==1]\n",
    "\n",
    "X = np.concatenate((X1,X2))\n",
    "y = np.concatenate((y1,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0], X[:,1], X[:,2], c = y,cmap = \"prism\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtaining the dominating dataset with $\\varepsilon \\le 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "l1 = a.dominatingSet(X1,y1,epsilon = 0.5)\n",
    "l2 = a.dominatingSet(X2,y2,epsilon = 0.5)\n",
    "Xsub = np.concatenate((X1[l1],X2[l2]))\n",
    "ysub = np.concatenate((y1[l1],y2[l2]))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Xsub[:,0], Xsub[:,1], Xsub[:,2], c = ysub, cmap = \"prism\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generation of a random dataset with the dominating dataset length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.sample(range(len(X)),len(Xsub))\n",
    "Xrand = X[random_index]\n",
    "yrand = y[random_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Xrand[:,0], Xrand[:,1], Xrand[:,2], c = yrand,cmap = \"prism\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perceptron training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several parameters can be tuned such as the number of iteration, the type of training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p.Perceptron(Xor = X,yor = y)\n",
    "p2 = p.Perceptron(Xor = X,yor = y)\n",
    "p3 = p.Perceptron(Xor = X,yor = y)\n",
    "\n",
    "v = np.random.random_sample((5,))\n",
    "p1.weight = v#[0.8]*5\n",
    "p2.weight = v#[0.8]*5\n",
    "p3.weight = v#[0.8]*5\n",
    "\n",
    "it = 100\n",
    "st = False\n",
    "p1.train(X,y,stochastic = st, iterations = it)\n",
    "p2.train(Xsub,ysub,stochastic = st, iterations = it)\n",
    "p3.train(Xrand,yrand,stochastic = st, iterations = it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy plots along the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = it\n",
    "# Plots of accuracy over themselves:\n",
    "\n",
    "orig = plt.plot(np.array(p1.history)[0:k], label = \"Original\")\n",
    "repRand = plt.plot(np.array(p3.history)[0:k], label = \"Random Dataset\")\n",
    "repSub = plt.plot(np.array(p2.history)[0:k], label = \"Dominating Dataset\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = plt.plot(np.array(p1.history_or)[0:k], label = \"Original\")\n",
    "repRand = plt.plot(np.array(p3.history_or)[0:k], label = \"Random Dataset\")\n",
    "repSub = plt.plot(np.array(p2.history_or)[0:k], label = \"Dominating Dataset\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 iterations of the training (Might take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 200\n",
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "for i in range(100):\n",
    "    random_index = random.sample(range(len(X)),len(Xsub))\n",
    "    Xrand = X[random_index]\n",
    "    yrand = y[random_index]\n",
    "    p1 = p.Perceptron(Xor = X,yor = y)\n",
    "    p2 = p.Perceptron(Xor = X,yor = y)\n",
    "    p3 = p.Perceptron(Xor = X,yor = y)\n",
    "    v = np.random.random_sample((5,))\n",
    "    p1.weight = v#[0.8]*5\n",
    "    p2.weight = v#[0.8]*5\n",
    "    p3.weight = v#[0.8]*5\n",
    "    p1.train(X,y,stochastic = st, iterations = it)\n",
    "    p2.train(Xsub,ysub,stochastic = st, iterations = it)\n",
    "    p3.train(Xrand,yrand,stochastic = st, iterations = it)\n",
    "    l1.append(p.output_over_dataset(X,p1))\n",
    "    l2.append(p.output_over_dataset(Xsub,p2))\n",
    "    l3.append(p.output_over_dataset(Xrand,p3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of the different errors through the 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = []\n",
    "for i in range(100):\n",
    "    e1.append(np.sum((l1[i][:,4]-y)**2)/len(X))\n",
    "e2 = []\n",
    "for i in range(100):\n",
    "    e2.append(np.sum((l2[i][:,4]-ysub)**2)/len(Xsub))\n",
    "e3 = []\n",
    "for i in range(100):\n",
    "    e3.append(np.sum((l3[i][:,4]-yrand)**2)/len(Xrand))\n",
    "e1 = np.array(e1)\n",
    "e2 = np.array(e2)\n",
    "e3 = np.array(e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interval of the error values for the original dataset: [\",np.min(e1),\",\",np.max(e1),\"]\")\n",
    "print(\"Interval of the error values for the dominating dataset: [\",np.min(e2),\",\",np.max(e2),\"]\")\n",
    "print(\"Interval of the error values for the random dataset: [\",np.min(e3),\",\",np.max(e3),\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Persistent homology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser, plot_dgms\n",
    "diagrams_or = ripser(X,maxdim=2)['dgms']\n",
    "diagrams_Sub = ripser(Xsub,maxdim=2)['dgms']\n",
    "diagrams_Rand = ripser(Xrand,maxdim=2)['dgms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original dataset\")\n",
    "plot_dgms(diagrams_or, show=True)\n",
    "print(\"Dominating dataset\")\n",
    "plot_dgms(diagrams_Sub, show=True)\n",
    "print(\"Random dataset\")\n",
    "plot_dgms(diagrams_Rand, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottleneck distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as g\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Sub[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Sub[1])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Dominating dataset and dimension 2 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[2], diagrams_Sub[2])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Rand[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Rand[1])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 2 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[2], diagrams_Rand[2])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hausdorff distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "print(\"Hausdorff distance between the original dataset and the dominating dataset: \",max(directed_hausdorff(X, Xsub)[0], directed_hausdorff(Xsub, X)[0]))\n",
    "print(\"Hausdorff distance between the original dataset and the random dataset: \",max(directed_hausdorff(X, Xrand)[0], directed_hausdorff(Xrand, X)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
