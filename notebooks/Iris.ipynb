{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import auxiliary_fun as a\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification as mk\n",
    "from keras.metrics import Precision, Recall, AUC, MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X1 = X[y==0]\n",
    "X2 = X[y==1]\n",
    "y1 = y[y==0]\n",
    "y2 = y[y==1]\n",
    "\n",
    "Xor = np.concatenate((X1,X2))\n",
    "yor = np.concatenate((y1,y2))\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Xor[:,0], Xor[:,1], Xor[:,2], c = yor,cmap = \"prism\")\n",
    "plt.savefig(\"iris_or.png\",dpi=360)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the dominating dataset with $\\varepsilon \\le 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "index = a.dominatingSet(Xor,yor,epsilon=0.5)\n",
    "Xsub=Xor[index]\n",
    "ysub=yor[index]\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Xsub[:,0], Xsub[:,1], Xsub[:,2], c = ysub, cmap = \"prism\")\n",
    "#plt.savefig(\"iris_dom.png\",dpi=360)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X=np.column_stack((Xor,yor))\n",
    "#np.random.shuffle(X)\n",
    "#Xor = X[:,0:4]\n",
    "#yor = X[:,4]\n",
    "#random_index = random.sample(range(len(Xor)),len(Xsub))\n",
    "#Xrand = Xor[random_index]\n",
    "#yrand = yor[random_index]\n",
    "#iris_random=np.column_stack((Xrand,yrand))\n",
    "#np.savetxt(\"iris_random2.txt\",iris_random)\n",
    "iris_random=np.loadtxt(\"data/iris_random.txt\")\n",
    "Xrand = iris_random[:,0:4]\n",
    "yrand = iris_random[:,4]\n",
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Xrand[:,0], Xrand[:,1], Xrand[:,2], c = yrand, cmap = \"prism\")\n",
    "#plt.savefig(\"iris_rand.png\",dpi=360)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a perceptron and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "n_features=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(5):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model1.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history1=model1.fit(Xor, yor,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=epochs,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l.append(model1.evaluate(Xor,yor,verbose=0))\n",
    "l = np.array(l)\n",
    "print(np.min(l[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "for i in range(5):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model2.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history2=model2.fit(Xsub, ysub,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=200,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l2.append(model2.evaluate(Xor,yor,verbose=0))\n",
    "np.min(np.array(l2)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(l2)[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = []\n",
    "for i in range(5):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model3.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    history3=model3.fit(Xrand, yrand, \n",
    "                        batch_size=1, \n",
    "                        epochs=epochs, \n",
    "                        verbose=False)\n",
    "    l3.append(model3.evaluate(Xor,yor,verbose=0))\n",
    "print(np.min(np.array(l3)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hausdorff distance and the bottleneck distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "print(\"Hausdorff distance between the original dataset and the dominating dataset: \",max(directed_hausdorff(Xor, Xsub)[0], directed_hausdorff(Xsub, Xor)[0]))\n",
    "print(\"Hausdorff distance between the original dataset and the random dataset: \",max(directed_hausdorff(Xor, Xrand)[0], directed_hausdorff(Xrand, Xor)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser\n",
    "diagrams_or = ripser(Xor,maxdim=2)['dgms']\n",
    "diagrams_Sub = ripser(Xsub,maxdim=2)['dgms']\n",
    "diagrams_Rand = ripser(Xrand,maxdim=2)['dgms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as g\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Sub[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Sub[1])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Rand[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Rand[1])\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
