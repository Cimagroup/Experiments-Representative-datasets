{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits dataset experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import auxiliary_fun as a\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load digits dataset and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "data = normalize(digits.data)\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Obtaining the dominating dataset with $\\varepsilon \\le 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "d0 = a.dominatingSet(data[y==0],y[y==0],epsilon = 0.2)\n",
    "d1 = a.dominatingSet(data[y==1],y[y==1],epsilon = 0.2)\n",
    "d2 = a.dominatingSet(data[y==2],y[y==2],epsilon = 0.2)\n",
    "d3 = a.dominatingSet(data[y==3],y[y==3],epsilon = 0.2)\n",
    "d4 = a.dominatingSet(data[y==4],y[y==4],epsilon = 0.2)\n",
    "d5 = a.dominatingSet(data[y==5],y[y==5],epsilon = 0.2)\n",
    "d6 = a.dominatingSet(data[y==6],y[y==6],epsilon = 0.2)\n",
    "d7 = a.dominatingSet(data[y==7],y[y==7],epsilon = 0.2)\n",
    "d8 = a.dominatingSet(data[y==8],y[y==8],epsilon = 0.2)\n",
    "d9 = a.dominatingSet(data[y==9],y[y==9],epsilon = 0.2)\n",
    "domdata = np.concatenate((data[y==0][d0],data[y==1][d1],data[y==2][d2],data[y==3][d3],data[y==4][d4],data[y==5][d5],data[y==6][d6],data[y==7][d7],data[y==8][d8],data[y==9][d9]))\n",
    "domy = np.concatenate((y[y==0][d0],y[y==1][d1],y[y==2][d2],y[y==3][d3],y[y==4][d4],y[y==5][d5],y[y==6][d6],y[y==7][d7],y[y==8][d8],y[y==9][d9]))\n",
    "end = time.time()\n",
    "print(abs(start-end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generation of a random dataset with the dominating dataset length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.sample(range(len(data)),len(domdata))\n",
    "Xrand = data[random_index]\n",
    "yrand = y[random_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perceptron training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = utils.to_categorical(y,10)\n",
    "domy = utils.to_categorical(domy,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(64,)))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start = time.time()\n",
    "model.fit(data, y, batch_size=len(data), epochs=100000, verbose=False)\n",
    "end = time.time()\n",
    "print(abs(start-end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=32, activation='sigmoid', input_shape=(64,)))\n",
    "model2.add(Dense(units=10, activation='softmax'))\n",
    "model2.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "start = time.time()\n",
    "model2.fit(domdata,domy , batch_size=len(domdata), epochs=100000, verbose=False)\n",
    "end = time.time()\n",
    "print(abs(start-end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 iteration of the training (Takes a lot of time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the original dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "for i in range(100):\n",
    "    random_index = random.sample(range(len(data)),len(domdata))\n",
    "    Xrand = data[random_index]\n",
    "    yrand = y[random_index]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='sigmoid', input_shape=(64,)))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(data,y , batch_size=1, epochs=20, verbose=False)\n",
    "    l1.append(model.evaluate(data,y)[1])\n",
    "    l2.append(model.evaluate(domdata,domy)[1])\n",
    "    l3.append(model.evaluate(Xrand,yrand)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics of the training over the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(l1))\n",
    "print(np.max(l2))\n",
    "print(np.max(l3))\n",
    "print(np.mean(l1))\n",
    "print(np.mean(l2))\n",
    "print(np.mean(l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation over original dataset: \",model.evaluate(data,y))\n",
    "print(\"Evaluation over dominating dataset: \",model.evaluate(domdata,domy))\n",
    "print(\"Evaluation over random dataset; \",model.evaluate(Xrand,yrand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dominating dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "for i in range(100):\n",
    "    \n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(units=32, activation='sigmoid', input_shape=(64,)))\n",
    "    model2.add(Dense(units=10, activation='softmax'))\n",
    "    model2.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model2.fit(domdata,domy , batch_size=1, epochs=9*20, verbose=False)\n",
    "    l1.append(model2.evaluate(domdata,domy)[1])\n",
    "    l2.append(model2.evaluate(data,y)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics of the training over the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(l1))\n",
    "print(np.max(l2))\n",
    "print(np.max(l3))\n",
    "print(np.mean(l1))\n",
    "print(np.mean(l2))\n",
    "print(np.mean(l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation over original dataset: \",model2.evaluate(data,y))\n",
    "print(\"Evaluation over dominating dataset: \",model2.evaluate(domdata,domy))\n",
    "print(\"Evaluation over random dataset; \",model2.evaluate(Xrand,yrand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the random dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "for i in range(100):\n",
    "    random_index = random.sample(range(len(data)),len(domdata))\n",
    "    Xrand = data[random_index]\n",
    "    yrand = y[random_index]\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(units=32, activation='sigmoid', input_shape=(64,)))\n",
    "    model3.add(Dense(units=10, activation='softmax'))\n",
    "    model3.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model3.fit(Xrand,yrand , batch_size=1, epochs=9*20, verbose=False)\n",
    "    l1.append(model3.evaluate(Xrand,yrand,verbose = 0)[1])\n",
    "    l2.append(model3.evaluate(data,y,verbose = 0)[1])\n",
    "print(\"Mean accuracy over itself:\",np.mean(np.array(l1)))\n",
    "print(\"Mean accuracy over full dataset:\",np.mean(np.array(l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(l1))\n",
    "print(np.max(l2))\n",
    "print(np.max(l3))\n",
    "print(np.mean(l1))\n",
    "print(np.mean(l2))\n",
    "print(np.mean(l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation over original dataset: \",model3.evaluate(data,y))\n",
    "print(\"Evaluation over dominating dataset: \",model3.evaluate(domdata,domy))\n",
    "print(\"Evaluation over random dataset; \",model3.evaluate(Xrand,yrand))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Persistent homology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser, plot_dgms\n",
    "diagrams_or = ripser(data,maxdim=0)['dgms']\n",
    "diagrams_Sub = ripser(domdata,maxdim=0)['dgms']\n",
    "diagrams_Rand = ripser(Xrand,maxdim=0)['dgms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original dataset\")\n",
    "plot_dgms(diagrams_or, show=True)\n",
    "print(\"Dominating dataset\")\n",
    "plot_dgms(diagrams_Sub, show=True)\n",
    "print(\"Random dataset\")\n",
    "plot_dgms(diagrams_Rand, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottleneck distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as g\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Sub[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for dominating dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Sub[1])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Dominating dataset and dimension 2 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[2], diagrams_Sub[2])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 0 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[0], diagrams_Rand[0])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 1 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[1], diagrams_Rand[1])\n",
    "print(message)\n",
    "message = \"Bottleneck distance for Random dataset and dimension 2 =\" + '%.2f' % g.bottleneck_distance(diagrams_or[2], diagrams_Rand[2])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hausdorff distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "print(\"Hausdorff distance between the original dataset and the dominating dataset: \",max(directed_hausdorff(data, domdata)[0], directed_hausdorff(domdata, data)[0]))\n",
    "print(\"Hausdorff distance between the original dataset and the random dataset: \",max(directed_hausdorff(data, Xrand)[0], directed_hausdorff(Xrand, data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. T-SNE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "RS = 123\n",
    "def fashion_scatter(x, colors):\n",
    "    # choose a color palette with seaborn.\n",
    "    num_classes = len(np.unique(colors))\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        # Position of each label at median of data points.\n",
    "\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "Xs_tsne_2D_or = TSNE(n_components=2,perplexity =55).fit_transform(data)\n",
    "fashion_scatter(Xs_tsne_2D_or, y)\n",
    "fashion_scatter(Xs_tsne_2D_or[index], y[index])\n",
    "fashion_scatter(Xs_tsne_2D_or[random_index], y[random_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
