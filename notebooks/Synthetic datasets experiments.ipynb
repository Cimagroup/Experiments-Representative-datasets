{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import auxiliary_fun as a\n",
    "from keras import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification as mk\n",
    "from keras.metrics import Precision, Recall, AUC, MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the following parameters can be changed to explore different casuistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "n_features = 2\n",
    "n_informative = 2\n",
    "n_redundant = 0\n",
    "n_classes = 2\n",
    "n_clusters_per_class= 1\n",
    "class_sep = [1.5]\n",
    "epsilon = [0.8]\n",
    "epochs = 100\n",
    "weights=[0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = mk(n_samples = n_samples, \n",
    "            n_features= n_features, \n",
    "            n_informative= n_informative, \n",
    "            n_redundant= n_redundant,\n",
    "            n_classes= n_classes,\n",
    "            n_clusters_per_class= n_clusters_per_class,\n",
    "            weights=weights,\n",
    "            class_sep = class_sep[0])\n",
    "data = r[0]\n",
    "labels = r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[:,0],data[:,1],c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "start = time.time()\n",
    "index = a.dominatingSet(X_train,y_train,epsilon=epsilon)\n",
    "end = time.time()\n",
    "print(abs(start-end))\n",
    "rep = X_train[index]\n",
    "labels_rep= y_train[index]\n",
    "labels_train = to_categorical(y_train,num_classes=2)\n",
    "labels_test = to_categorical(y_test,num_classes=2)\n",
    "labels_rep_train = to_categorical(labels_rep,num_classes=2)\n",
    "random_index = random.sample(range(len(X_train)),len(rep))\n",
    "rand = data[random_index]\n",
    "labels_rand = labels[random_index]\n",
    "labels_rand_train = to_categorical(labels_rand,num_classes=2)\n",
    "labels_cat = to_categorical(labels,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rep[:,0],rep[:,1],c=labels_rep)\n",
    "#plt.savefig('3_binary_class_dominating_data.png',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(rand[:,0],rand[:,1],c=labels_rand)\n",
    "#plt.savefig('3_binary_class_random_data.png',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(5):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model1.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history1=model1.fit(X_train, y_train,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=epochs,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l.append(model1.evaluate(X_test,y_test,verbose=0))\n",
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "for i in range(5):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model2.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history2=model2.fit(rep, labels_rep,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=epochs,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l2.append(model2.evaluate(X_test,y_test,verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = np.array(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l2[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(l2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = []\n",
    "for i in range(5):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(units=1, activation='sigmoid',input_shape=(n_features,)))\n",
    "    model3.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    history3=model3.fit(rand, labels_rand, \n",
    "                        batch_size=1, \n",
    "                        epochs=epochs, \n",
    "                        verbose=False)\n",
    "    l3.append(model3.evaluate(X_test,y_test,verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = np.array(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l3[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "n_features = 3\n",
    "n_informative = 2\n",
    "n_redundant = 0\n",
    "n_classes = 2\n",
    "n_clusters_per_class= 1\n",
    "class_sep = [0.5]\n",
    "epsilon = [0.3]\n",
    "epochs = 20\n",
    "weights=[0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = mk(n_samples = n_samples, \n",
    "            n_features= n_features, \n",
    "            n_informative= n_informative, \n",
    "            n_redundant= n_redundant,\n",
    "            n_classes= n_classes,\n",
    "            n_clusters_per_class= n_clusters_per_class,\n",
    "            weights=weights,\n",
    "            class_sep = class_sep[0])\n",
    "data = r[0]\n",
    "labels = r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(data[:,0], data[:,1], data[:,2], c = labels,cmap = \"prism\")\n",
    "plt.savefig('5_binary_class_original_data.png',dpi=500)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "start = time.time()\n",
    "index = a.dominatingSet(X_train,y_train,epsilon=epsilon)\n",
    "end = time.time()\n",
    "print(abs(start-end))\n",
    "rep = X_train[index]\n",
    "labels_rep= y_train[index]\n",
    "random_index = random.sample(range(len(X_train)),len(rep))\n",
    "rand = data[random_index]\n",
    "labels_rand = labels[random_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X_train[:,0], X_train[:,1], X_train[:,2], c = y_train,cmap = \"prism\")\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(rep[:,0], rep[:,1], rep[:,2], c = labels_rep,cmap = \"prism\")\n",
    "plt.savefig('5_binary_class_dominating_data.png',dpi=500)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(rand[:,0], rand[:,1], rand[:,2], c = labels_rand,cmap = \"prism\")\n",
    "plt.savefig('5_binary_class_rand_data.png',dpi=500)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(5):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(units=12, activation='relu', input_shape=(n_features,)))\n",
    "    model1.add(Dense(units=6, activation='relu'))\n",
    "    model1.add(Dense(units=1, activation='sigmoid'))\n",
    "    model1.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history1=model1.fit(X_train, y_train,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=epochs,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l.append(model1.evaluate(X_test,y_test,verbose=0))\n",
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "for i in range(5):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(units=12, activation='relu', input_shape=(n_features,)))\n",
    "    model2.add(Dense(units=6, activation='relu'))\n",
    "    model2.add(Dense(units=1, activation='sigmoid'))\n",
    "    model2.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    import time\n",
    "    start = time.time()\n",
    "    history2=model2.fit(rep, labels_rep,batch_size=1, \n",
    "                                #batch_size=1,\n",
    "                                #validation_split = val_split, \n",
    "                                epochs=epochs,\n",
    "                                verbose=False)\n",
    "    end = time.time()\n",
    "    print(abs(start-end))\n",
    "    l2.append(model2.evaluate(X_test,y_test,verbose=0))\n",
    "l2 = np.array(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l2[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = []\n",
    "for i in range(5):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(units=12, activation='relu', input_shape=(n_features,)))\n",
    "    model3.add(Dense(units=6, activation='relu'))\n",
    "    model3.add(Dense(units=1, activation='sigmoid'))\n",
    "    model3.compile(optimizer=\"SGD\", loss='MSE', metrics=['accuracy',Recall(), Precision(),AUC(),MeanSquaredError()])\n",
    "    history3=model3.fit(rand, labels_rand, \n",
    "                        batch_size=1, \n",
    "                        epochs=epochs, \n",
    "                        verbose=False)\n",
    "    l3.append(model3.evaluate(X_test,y_test,verbose=0))\n",
    "l3 = np.array(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l3[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history3.history['accuracy'])\n",
    "plt.legend(['original', 'Representative','Random'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
